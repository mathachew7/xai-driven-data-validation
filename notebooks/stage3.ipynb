{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920e5dfe",
   "metadata": {},
   "source": [
    "### Stage 3: Predictive Modeling â€“ Explanation\n",
    "\n",
    "Having prepared and partitioned the data in Stage 2, we now move into the modeling phase, where the goal is to build predictive models that estimate the likelihood of a patient being readmitted within 30 days of hospital discharge.\n",
    "\n",
    "Unlike traditional workflows that focus solely on performance metrics, this stage is a **setup for diagnosis**. Our objective is not just to train a model that performs well, but to observe how various model architectures behave under the constraints and imperfections of real-world clinical data.\n",
    "\n",
    "This stage is especially important for our research because:\n",
    "- It provides **empirical evidence** that traditional models can exhibit poor behavior (e.g., ignoring the minority class).\n",
    "- It creates **predictive outputs** that XAI techniques (like SHAP and LIME) will later dissect to expose hidden issues.\n",
    "- It allows us to test whether data problems generalize across model types, reinforcing our claim that **XAI is required to explain not just models, but the data they depend on.**\n",
    "\n",
    "We will:\n",
    "- Load the preprocessed train/test datasets.\n",
    "- Train a set of classifiers including tree-based, linear, and neural architectures.\n",
    "- Evaluate each model using both performance metrics and error patterns.\n",
    "\n",
    "This sets the stage for XAI to uncover *why* these models behave the way they do, especially when they fail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8334c4",
   "metadata": {},
   "source": [
    "### Step 1: Load Preprocessed Data\n",
    "\n",
    "We begin Stage 3 by loading the cleaned and partitioned training and testing datasets that were saved at the end of Stage 2. This ensures consistency across experimental stages and allows us to evaluate multiple models on the exact same splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8df3edaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded successfully\n",
      "Train shape: (79593, 44)\n",
      "Test shape: (19899, 44)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load data\n",
    "X_train = joblib.load('../data/X_train.pkl')\n",
    "X_test = joblib.load('../data/X_test.pkl')\n",
    "y_train = joblib.load('../data/y_train.pkl')\n",
    "y_test = joblib.load('../data/y_test.pkl')\n",
    "\n",
    "print(\"âœ… Data loaded successfully\")\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab4174c",
   "metadata": {},
   "source": [
    "### Step 2: Train First Model â€“ Random Forest Classifier\n",
    "\n",
    "We begin with a Random Forest classifier as our baseline model. It is widely used in healthcare prediction tasks due to its robustness, ability to handle non-linear relationships, and compatibility with explainability tools like SHAP's TreeExplainer.\n",
    "\n",
    "This model also naturally handles missing values and does not require feature scaling, making it an ideal starting point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0050b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Random Forest model trained and saved.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(rf_model, '../models/random_forest.pkl')\n",
    "\n",
    "print(\"âœ… Random Forest model trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2636b1",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate Random Forest Model\n",
    "\n",
    "We now evaluate the performance of the trained Random Forest model using classification metrics that are especially relevant in imbalanced classification tasks, including:\n",
    "- **Precision** (positive predictive value)\n",
    "- **Recall** (sensitivity)\n",
    "- **F1-score** (balance of precision and recall)\n",
    "- **ROC AUC** (model's ability to rank positives over negatives)\n",
    "\n",
    "We will also examine the **confusion matrix** to understand the modelâ€™s behavior in terms of false positives and false negatives â€” which is critical in high-stakes domains like healthcare.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "227304c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Classification Report (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8879    0.9997    0.9405     17665\n",
      "           1     0.4444    0.0018    0.0036      2234\n",
      "\n",
      "    accuracy                         0.8877     19899\n",
      "   macro avg     0.6662    0.5008    0.4720     19899\n",
      "weighted avg     0.8381    0.8877    0.8353     19899\n",
      "\n",
      "ðŸ“ˆ Confusion Matrix:\n",
      "[[17660     5]\n",
      " [ 2230     4]]\n",
      "ðŸ”µ ROC AUC Score: 0.6427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Predictions and probabilities\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "print(\"ðŸ“Š Classification Report (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_rf, digits=4))\n",
    "\n",
    "print(\"ðŸ“ˆ Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "print(f\"ðŸ”µ ROC AUC Score: {roc_auc_score(y_test, y_proba_rf):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534dba19",
   "metadata": {},
   "source": [
    "### Random Forest Model â€“ Performance Interpretation\n",
    "\n",
    "The Random Forest classifier achieves an overall accuracy of **88.8%**, but this metric masks severe performance issues on the minority class (`1`: readmitted within 30 days), which is the clinically important outcome.\n",
    "\n",
    "#### Key observations:\n",
    "\n",
    "- **Majority Class (`0`) Performance:**\n",
    "  - Precision: **0.89**\n",
    "  - Recall: **~100%**\n",
    "  - F1-score: **0.94**\n",
    "  - The model almost perfectly identifies patients *not* readmitted, which dominates the test set.\n",
    "\n",
    "- **Minority Class (`1`) Failure:**\n",
    "  - Precision: **0.44** (only 4 predicted as positive)\n",
    "  - Recall: **0.0018** (only 4 of 2,234 true positives detected)\n",
    "  - F1-score: **0.0036** â€” effectively **non-functional** for predicting actual readmissions\n",
    "\n",
    "- **ROC AUC Score:**  \n",
    "  - **0.6427**, indicating some rank-order separation between classes, but **not sufficient for clinical use**.\n",
    "\n",
    "- **Confusion Matrix:**  \n",
    "  - Only 4 of the 2,234 true positive cases were correctly identified.\n",
    "  - The model is **heavily skewed toward the majority class**, likely due to class imbalance and overfitting to frequent patterns.\n",
    "\n",
    "#### Why This Matters for XAI:\n",
    "\n",
    "This result underscores a core problem in trust and model validation:\n",
    "> A model may appear performant on paper (high accuracy), yet completely fail in the scenarios that matter most â€” and **traditional metrics wonâ€™t explain why**.\n",
    "\n",
    "This behavior now becomes a case for **Stage 4**, where SHAP will help uncover:\n",
    "- What features the model *is* using (and overusing)\n",
    "- What signals it *misses*\n",
    "- Whether any proxy variables (e.g., race, admission type) dominate decision logic unfairly\n",
    "\n",
    "This failure is not a setback â€” it's the **exact justification for explainable validation** in high-stakes domains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb2915",
   "metadata": {},
   "source": [
    "### Step 4: Train XGBoost Classifier\n",
    "\n",
    "XGBoost is a powerful gradient-boosted tree ensemble method known for its ability to model complex feature interactions and handle imbalanced datasets effectively. It also integrates seamlessly with SHAP for global and local explanation, making it an excellent candidate for comparison in our framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d787e4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… XGBoost model trained and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subashyadav/Documents/projects/xai_validation/.venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:52:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# Initialize XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=8,  # handle class imbalance\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(xgb_model, '../models/xgboost.pkl')\n",
    "\n",
    "print(\"âœ… XGBoost model trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31bac02",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate XGBoost Model\n",
    "\n",
    "We now assess the performance of the XGBoost classifier, a gradient-boosted decision tree model known for robustness on structured data. This evaluation provides a direct comparison to the Random Forest model and helps us understand if a boosting-based method better captures the nuances in this imbalanced dataset.\n",
    "\n",
    "We focus on:\n",
    "- **Classification Report** for precision, recall, F1-score\n",
    "- **Confusion Matrix** to analyze false positives/negatives\n",
    "- **ROC AUC** for overall separability of the classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e10f544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Classification Report (XGBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9183    0.7219    0.8083     17665\n",
      "           1     0.1828    0.4919    0.2666      2234\n",
      "\n",
      "    accuracy                         0.6961     19899\n",
      "   macro avg     0.5505    0.6069    0.5374     19899\n",
      "weighted avg     0.8357    0.6961    0.7475     19899\n",
      "\n",
      "ðŸ“ˆ Confusion Matrix:\n",
      "[[12752  4913]\n",
      " [ 1135  1099]]\n",
      "ðŸ”µ ROC AUC Score: 0.6515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"ðŸ“Š Classification Report (XGBoost):\")\n",
    "print(classification_report(y_test, y_pred_xgb, digits=4))\n",
    "\n",
    "print(\"ðŸ“ˆ Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "\n",
    "print(\"ðŸ”µ ROC AUC Score:\", round(roc_auc_score(y_test, y_proba_xgb), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a40194",
   "metadata": {},
   "source": [
    "### âœ… Evaluation Summary: XGBoost Model\n",
    "\n",
    "The XGBoost classifier demonstrates significantly different behavior from the earlier Random Forest, especially in handling the minority class (patients readmitted within 30 days):\n",
    "\n",
    "#### ðŸ”¹ Improved Recall for Minority Class (Positive)\n",
    "\n",
    "- Recall for class `1` (`<30` readmission) improved drastically to **~49.2%**, up from **~0.2%** in the Random Forest model.\n",
    "- This suggests that XGBoost is better at identifying patients at risk of early readmission â€” a **clinically vital** outcome in high-stakes healthcare settings.\n",
    "\n",
    "#### ðŸ”¹ Tradeoff in Precision\n",
    "\n",
    "- Precision for the positive class dropped to **~18%**, meaning many false positives.\n",
    "- However, in healthcare, **high recall is often prioritized over precision** â€” better to flag potential readmissions than miss them.\n",
    "\n",
    "#### ðŸ”¹ Overall Performance\n",
    "\n",
    "- **Accuracy:** ~69.6%  \n",
    "- **ROC AUC:** **0.6515**, showing improved class separability compared to Random Forest (**0.6427**).\n",
    "\n",
    "#### ðŸ”¹ Confusion Matrix Insights\n",
    "\n",
    "- XGBoost correctly classified **1,099** out of **2,234** positive cases, unlike Random Forest which only captured **4**.\n",
    "- However, it incorrectly flagged **4,913** negative cases as positive.\n",
    "\n",
    "#### ðŸ”¹ Interpretability Implications\n",
    "\n",
    "- This result makes **XGBoost a prime candidate for SHAP-based explainability**, since it is capturing nuanced feature interactions that traditional models missed.\n",
    "- We will later inspect if these improvements come from **valid clinical signals** or **data artifacts**, using SHAP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9146cf1",
   "metadata": {},
   "source": [
    "### ðŸ”¸ Description:\n",
    "\n",
    "In this step, we train a **Multilayer Perceptron (MLP)** neural network using scikit-learnâ€™s `MLPClassifier`. Unlike decision trees or gradient boosting, neural networks can capture **nonlinear relationships** and **interactions** in the data. Although they are less interpretable out-of-the-box, they provide an important contrast for later **SHAP-based analysis**.\n",
    "\n",
    "This MLP configuration includes:\n",
    "\n",
    "- Two hidden layers with **64** and **32** neurons respectively.  \n",
    "- **ReLU** activation function.  \n",
    "- **Adam** optimizer.  \n",
    "- A maximum of **100 training iterations**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abd98008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subashyadav/Documents/projects/xai_validation/.venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/mlp_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import joblib\n",
    "\n",
    "# Initialize and train MLP model\n",
    "mlp_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained MLP model\n",
    "joblib.dump(mlp_model, '../models/mlp_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8130e6cc",
   "metadata": {},
   "source": [
    "ðŸ”¸ Description:\n",
    "We now assess the performance of our trained MLP model on the test set using standard classification metrics and ROC AUC score. This ensures consistent comparison across all models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5def16c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Classification Report (MLP):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     17665\n",
      "           1       0.41      0.01      0.02      2234\n",
      "\n",
      "    accuracy                           0.89     19899\n",
      "   macro avg       0.65      0.50      0.48     19899\n",
      "weighted avg       0.83      0.89      0.84     19899\n",
      "\n",
      "ðŸ“ˆ Confusion Matrix:\n",
      "[[17630    35]\n",
      " [ 2210    24]]\n",
      "ðŸ”µ ROC AUC Score: 0.6318\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "y_proba_mlp = mlp_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"ðŸ“Š Classification Report (MLP):\")\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "print(\"ðŸ“ˆ Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_mlp))\n",
    "\n",
    "print(\"ðŸ”µ ROC AUC Score:\", round(roc_auc_score(y_test, y_proba_mlp), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ce05b",
   "metadata": {},
   "source": [
    "### âœ… Evaluation Summary: MLP Neural Network\n",
    "\n",
    "The MLP classifier shows similar overall behavior to the Random Forest but falls short of the improvements seen with XGBoost, particularly on the minority class.\n",
    "\n",
    "\n",
    "#### ðŸ”¹ Strengths:\n",
    "- **High accuracy**: ~89%, largely driven by strong performance on the majority class (`readmitted = 0`).\n",
    "- **Precision (class 0)**: The model is highly precise and accurate when identifying patients *not* readmitted within 30 days.\n",
    "\n",
    "\n",
    "#### ðŸ”¹ Weaknesses:\n",
    "- **Poor minority class recall**: Only **~1%** of the patients actually readmitted within 30 days were correctly identified.\n",
    "- **Low ROC AUC**: At **0.6318**, this indicates poor class separation and little learned discriminatory power for the positive class.\n",
    "- **False Negatives**: 2,210 patients predicted as not readmitted when they actually were â€” a major clinical concern.\n",
    "\n",
    "\n",
    "#### ðŸ”¹ Interpretation:\n",
    "Despite the MLPâ€™s nonlinear modeling ability, it struggles with the **severe class imbalance**. The lack of positive class sensitivity makes it unsuitable as-is for high-stakes clinical tasks â€” though it's still useful as a contrast during SHAP analysis to test how differently MLPs learn compared to tree-based models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369d9d45",
   "metadata": {},
   "source": [
    "## âœ… Stage 3 Summary: Model Training & Evaluation\n",
    "\n",
    "In this stage, we trained and evaluated three different classifiers â€” **Random Forest**, **XGBoost**, and **Multilayer Perceptron (MLP)** â€” on the processed hospital readmission dataset. The primary objective was not only to assess predictive power but also to set up a robust foundation for subsequent **XAI-driven analysis** that can reveal **hidden data quality issues, biases, and model dependencies**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¢ Performance Comparison\n",
    "\n",
    "| Metric             | Random Forest       | XGBoost              | MLP (Neural Net)     |\n",
    "|--------------------|---------------------|----------------------|-----------------------|\n",
    "| **Accuracy**       | 88.8%               | 69.6%                | 89.0%                 |\n",
    "| **Recall (Class 1)** | 0.18%              | 49.2%                | 1.1%                  |\n",
    "| **Precision (Class 1)** | 44.4%           | 18.3%                | 41.0%                 |\n",
    "| **F1-Score (Class 1)** | 0.36%            | 26.7%                | 2.0%                  |\n",
    "| **ROC AUC**        | 0.6427              | **0.6515**           | 0.6318                |\n",
    "| **TP (Class 1)**   | 4                   | **1,099**            | 24                    |\n",
    "| **FP (Class 1)**   | 5                   | 4,913                | 35                    |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Interpretation & Alignment with XAI-Driven Validation Goals\n",
    "\n",
    "#### 1. **Random Forest:**\n",
    "- Strong accuracy and precision for the majority class.\n",
    "- Fails completely at identifying early readmissions (**Recall: 0.18%**), making it **clinically unreliable**.\n",
    "- This model may appear performant on surface metrics but hides its failure on minority prediction â€” a classic example of **false confidence**, perfect for SHAP analysis to investigate **why**.\n",
    "\n",
    "#### 2. **XGBoost:**\n",
    "- Shows **balanced sensitivity**, correctly identifying nearly **50% of early readmissions**.\n",
    "- Accepts a precision tradeoff â€” which in healthcare is **justifiable** to avoid missing high-risk patients.\n",
    "- Best candidate for **explainability**: exhibits nuanced, non-linear feature dependencies that SHAP can expose.\n",
    "- Ideal for validating the frameworkâ€™s **core claim** â€” that XAI can surface hidden model behaviors and implicit data flaws.\n",
    "\n",
    "#### 3. **Multilayer Perceptron (MLP):**\n",
    "- Excellent accuracy but suffers the same problem as Random Forest â€” poor sensitivity to the minority class.\n",
    "- Captures complex patterns, but its **black-box nature** reinforces the need for **explainability techniques** like SHAP.\n",
    "- Useful as a neural baseline but not suitable for high-stakes settings without deeper interpretation.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Conclusion\n",
    "\n",
    "This modeling phase illustrates that traditional performance metrics can be **misleading**, especially in imbalanced, high-risk scenarios like hospital readmission prediction. XGBoost, despite lower accuracy, surfaces more **clinically relevant signals**, making it a strong candidate for explainability.\n",
    "\n",
    "This sets the stage for **Stage 4: SHAP-based Explainability**, where we will:\n",
    "- Investigate **which features** drive model predictions.\n",
    "- Identify **data segments** or attributes disproportionately affecting predictions.\n",
    "- Detect **anomalies**, **biases**, or **proxy features** that would be invisible in traditional validation.\n",
    "\n",
    "By aligning model outputs with explainable insights, we validate our central thesis: **XAI is not just for model interpretation but is a critical component for proactive, trust-centric data validation**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5aadef",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
