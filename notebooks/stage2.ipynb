{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "338233cb",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Stage 2: Data Preprocessing for XAI-Compatible Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a13b16",
   "metadata": {},
   "source": [
    "This preprocessing stage transforms raw hospital encounter data into a structured format ready for machine learning, while intentionally preserving features and patterns that XAI tools can later interrogate. Rather than aggressively \"cleaning\" the data to perfection, we apply *strategic preparation* that supports both modeling and explainability.\n",
    "\n",
    "Key actions and their relevance:\n",
    "\n",
    "1. **Identifier Removal:**  \n",
    "   Dropping `encounter_id` and `patient_nbr` prevents leakage of non-predictive, uniquely identifying information into the model, ensuring that predictions are driven by clinical or contextual features ‚Äî not row IDs.\n",
    "\n",
    "2. **Missing Value Normalization:**  \n",
    "   We replaced all `'?'` placeholders with proper `NaN` values. This is essential because most validation or imputation logic depends on standard missing value representations. It also allows SHAP to later reveal if imputed or missing features contribute disproportionately to predictions.\n",
    "\n",
    "3. **Target Mapping (`readmitted_binary`):**  \n",
    "   The original readmission target had three classes. We focus on a binary classification: predicting **whether a patient will be readmitted within 30 days** (1) or not (0). This is both clinically relevant and consistent with literature.\n",
    "\n",
    "4. **Invalid Demographic Cleanup:**  \n",
    "   Rows with unknown gender or missing race were removed. This avoids introducing ambiguous demographic signals that could complicate both model fairness and interpretation through XAI later.\n",
    "\n",
    "5. **Selective Feature Dropping:**  \n",
    "   Features with extremely high missingness (e.g., `weight`, `payer_code`, `medical_specialty`) were dropped. While these may be interesting, their sparsity could create misleading patterns during model training and SHAP analysis.\n",
    "\n",
    "6. **Label Encoding for Categorical Features:**  \n",
    "   All string-based categorical features were label encoded. This preserves their ordinal relationship for tree-based models (e.g., Random Forest, XGBoost) while maintaining interpretability through SHAP's internal mappings.\n",
    "\n",
    "7. **Stratified Train-Test Split:**  \n",
    "   We split the dataset using stratified sampling on the binary readmission label. This preserves the original imbalance and ensures a representative test set for evaluation and explanation.\n",
    "\n",
    "This stage sets the foundation for interpretable modeling. By cleaning with intent ‚Äî rather than aggressively eliminating all irregularities ‚Äî we leave room for XAI tools to detect subtle biases, outliers, and inconsistencies later on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217b5d0",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5248bebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1  ...          No      No                   No   \n",
       "1                 3  ...          No      Up                   No   \n",
       "2                 2  ...          No      No                   No   \n",
       "3                 2  ...          No      Up                   No   \n",
       "4                 1  ...          No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/diabetic_data.csv')\n",
    "\n",
    "# Preview top rows\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab69c41",
   "metadata": {},
   "source": [
    "### Step 1: Drop Identifiers\n",
    "\n",
    "`encounter_id` and `patient_nbr` are identifiers, not features. Including them could lead to data leakage or distort model learning.\n",
    "\n",
    "We drop:\n",
    "- `encounter_id` (unique per visit)\n",
    "- `patient_nbr` (can be used later for longitudinal grouping but excluded for now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6849be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['encounter_id', 'patient_nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea6eb20",
   "metadata": {},
   "source": [
    "### Step 2: Replace '?' with NaN\n",
    "\n",
    "Many features use `'?'` as a placeholder for missing data, which is not recognized by Pandas as null. We replace all such instances with `np.nan` for correct downstream processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaeca98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df.replace('?', np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5548c395",
   "metadata": {},
   "source": [
    "### Step 3: Filter Ambiguous or Invalid Entries\n",
    "\n",
    "We remove:\n",
    "- Rows where gender is `Unknown/Invalid`\n",
    "- Optionally, rows with missing race (to ensure cleaner bias analysis later)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f94c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ambiguous gender\n",
    "df = df[df['gender'] != 'Unknown/Invalid']\n",
    "\n",
    "# Remove rows with missing race\n",
    "df = df[df['race'].notna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5384c63",
   "metadata": {},
   "source": [
    "### Step 4: Encode Target Variable\n",
    "\n",
    "We define a binary target:\n",
    "- `1` ‚Üí Readmitted **within 30 days** (`'<30'`)\n",
    "- `0` ‚Üí Not readmitted or readmitted after 30 days (`'NO'`, `'>30'`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79db0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readmitted_binary\n",
       "0    88323\n",
       "1    11169\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['readmitted_binary'] = df['readmitted'].apply(lambda x: 1 if x == '<30' else 0)\n",
    "df['readmitted_binary'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72508ab",
   "metadata": {},
   "source": [
    "### Step 5: Handle High-Missing Columns\n",
    "\n",
    "We drop `weight`, `payer_code`, and `medical_specialty` due to high missing values (~40-97%) that could distort model learning. These features may be revisited later if needed for advanced imputation/XAI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8a251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['weight', 'payer_code', 'medical_specialty'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82b14af",
   "metadata": {},
   "source": [
    "### Step 6: Encode Categorical Variables\n",
    "\n",
    "To ensure model compatibility, we encode all remaining object-type columns using Label Encoding.\n",
    "\n",
    "Note:\n",
    "- One-Hot Encoding could explode dimensionality (too many categories)\n",
    "- Label encoding preserves interpretability for SHAP, especially for tree models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "980ee039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = df.select_dtypes(include='object').columns.drop('readmitted')  # exclude original target\n",
    "label_encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223c64a",
   "metadata": {},
   "source": [
    "### Step 7: Split Data for Modeling\n",
    "\n",
    "We split into training and testing sets using stratified sampling to preserve the original distribution of the target variable (`readmitted_binary`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bb1ffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (79593, 44)\n",
      "Test shape: (19899, 44)\n",
      "Positive class rate in train: 0.11225861570741145\n",
      "Positive class rate in test: 0.11226694808784361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['readmitted', 'readmitted_binary'])\n",
    "y = df['readmitted_binary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Positive class rate in train:\", y_train.mean())\n",
    "print(\"Positive class rate in test:\", y_test.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f85872",
   "metadata": {},
   "source": [
    "### Class Balance & Data Split Interpretation:\n",
    "\n",
    "The target variable `readmitted_binary` shows a significant **class imbalance**:\n",
    "- 88,323 instances (‚âà 89%) belong to the **negative class** (`0`: not readmitted within 30 days).\n",
    "- 11,169 instances (‚âà 11%) belong to the **positive class** (`1`: readmitted within 30 days).\n",
    "\n",
    "This imbalance is clinically consistent ‚Äî most patients are not readmitted within 30 days ‚Äî but poses a **modeling challenge**, as naive classifiers may favor the majority class.\n",
    "\n",
    "To mitigate this during evaluation and explanation, we applied **stratified splitting**, ensuring:\n",
    "- Training set: 79,593 samples\n",
    "- Test set: 19,899 samples\n",
    "- Class proportions are preserved across both sets (~11.2% positive rate)\n",
    "\n",
    "Maintaining class distribution across splits is **essential for fair model evaluation** and for XAI to uncover insights across both frequent and rare cases (e.g., why a rare 30-day readmission is predicted).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c96a82b",
   "metadata": {},
   "source": [
    "### Cleaned & Encoded Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46ab1e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/cleaned_diabetes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020744f2",
   "metadata": {},
   "source": [
    "### üîπ 2. Train/Test Splits\n",
    "Saving the final X_train, X_test, y_train, y_test as .pkl or .csv so Stage 3 can load directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d7c2fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/y_test.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(X_train, '../data/X_train.pkl')\n",
    "joblib.dump(X_test, '../data/X_test.pkl')\n",
    "joblib.dump(y_train, '../data/y_train.pkl')\n",
    "joblib.dump(y_test, '../data/y_test.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ede3e1",
   "metadata": {},
   "source": [
    "### üîπ 3. Label Encoders (if needed in SHAP explanations)\n",
    "If reverse-transform encoded categorical values in SHAP outputs, saving the label_encoders dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1596f9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/label_encoders.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(label_encoders, '../data/label_encoders.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585df94b",
   "metadata": {},
   "source": [
    "### Overall Conclusion ‚Äì Stage 2: Data Preprocessing\n",
    "\n",
    "This stage successfully transformed the raw diabetes hospitalization dataset into a structured, model-ready format, while **intentionally preserving signals of data quality and potential bias** for later explainability analysis.\n",
    "\n",
    "Key outcomes include:\n",
    "\n",
    "- ‚úÖ **Identifier features** were dropped to prevent leakage.\n",
    "- ‚úÖ **Placeholder values** (`'?'`) were normalized to `NaN`, allowing proper handling and future interpretability.\n",
    "- ‚úÖ **Target variable (`readmitted`)** was converted to a binary outcome: predicting whether a patient will be readmitted within 30 days ‚Äî a clinically meaningful and high-stakes decision.\n",
    "- ‚úÖ **Demographic filters** (e.g., removing unknown gender) ensured that fairness analysis will not be contaminated by invalid data.\n",
    "- ‚úÖ **Categorical variables** were label encoded in a SHAP-compatible manner, preserving feature semantics for downstream explanations.\n",
    "- ‚úÖ **Train-test split** was performed using stratified sampling to retain the original class imbalance across both sets, ensuring fair and trustworthy model evaluation.\n",
    "\n",
    "This preprocessing approach reflects a core tenet of our framework: rather than over-cleaning the data, we **strategically structure it** so that **explainable AI techniques can later uncover what traditional validation might miss** ‚Äî including subtle patterns of bias, inconsistency, and trust degradation.\n",
    "\n",
    "With the data now partitioned and cleaned, we proceed to Stage 3: model training ‚Äî the first point where we‚Äôll observe how these decisions affect predictive performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
